{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c32ef1ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13712,
     "status": "ok",
     "timestamp": 1731428314304,
     "user": {
      "displayName": "킹승영",
      "userId": "12420221722795178737"
     },
     "user_tz": -540
    },
    "id": "c32ef1ce",
    "outputId": "7d11855a-5f4e-4f6e-a4e0-a7cdd02cae95",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.2.7-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.16 (from langchain-openai)\n",
      "  Downloading langchain_core-0.3.16-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting openai<2.0.0,>=1.54.0 (from langchain-openai)\n",
      "  Downloading openai-1.54.4-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.16->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.16->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.16->langchain-openai) (0.1.139)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.16->langchain-openai) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.16->langchain-openai) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.16->langchain-openai) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.16->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (4.66.6)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain-openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain-openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain-openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain-openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.16->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.16->langchain-openai) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.16->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.16->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.16->langchain-openai) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.3)\n",
      "Downloading langchain_openai-0.2.7-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.16-py3-none-any.whl (409 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.2/409.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.54.4-py3-none-any.whl (389 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.6/389.6 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tiktoken, openai, langchain-core, langchain-openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.52.2\n",
      "    Uninstalling openai-1.52.2:\n",
      "      Successfully uninstalled openai-1.52.2\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.15\n",
      "    Uninstalling langchain-core-0.3.15:\n",
      "      Successfully uninstalled langchain-core-0.3.15\n",
      "Successfully installed langchain-core-0.3.16 langchain-openai-0.2.7 openai-1.54.4 tiktoken-0.8.0\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ad10f98",
   "metadata": {
    "executionInfo": {
     "elapsed": 12429,
     "status": "ok",
     "timestamp": 1731428329805,
     "user": {
      "displayName": "킹승영",
      "userId": "12420221722795178737"
     },
     "user_tz": -540
    },
    "id": "1ad10f98",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a0398b",
   "metadata": {
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1731428361906,
     "user": {
      "displayName": "킹승영",
      "userId": "12420221722795178737"
     },
     "user_tz": -540
    },
    "id": "e1a0398b"
   },
   "outputs": [],
   "source": [
    "# OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
    "OPENAI_API_KEY = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93b6e70",
   "metadata": {
    "id": "e93b6e70"
   },
   "source": [
    "### chain이란?\n",
    "- 한 task의 출력이 다음 task의 input이 됨\n",
    "- chain 종류 3가지. (어떤 chain을 구성할지에 대한)\n",
    "  - utility\n",
    "  - generic\n",
    "  - combine document\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721594a1",
   "metadata": {
    "id": "721594a1"
   },
   "source": [
    "#### ex. prompt에 수식을 계산해달라고 하면?\n",
    "- 계산을 실제로 하는게 아니라 패턴을 학습하는 것임.\n",
    "- 여러 계산 수식을 하는 원리가 학습되어 있음.\n",
    "- lstm으로 계산을 예측함.\n",
    "- 플러그인>수식을 생성>플러그인 사용>답>llm 답변 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e659765",
   "metadata": {
    "id": "0e659765"
   },
   "source": [
    "### 1. utility chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e128d96",
   "metadata": {
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1731428365401,
     "user": {
      "displayName": "킹승영",
      "userId": "12420221722795178737"
     },
     "user_tz": -540
    },
    "id": "5e128d96"
   },
   "outputs": [],
   "source": [
    "# LLMMathChain: 수학 계산을 위한 Utility Chain\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMMathChain\n",
    "openai = ChatOpenAI(\n",
    "    model_name = 'gpt-3.5-turbo',\n",
    "    temperature = 0,\n",
    "    api_key = OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d82d9a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1753,
     "status": "ok",
     "timestamp": 1731428368066,
     "user": {
      "displayName": "킹승영",
      "userId": "12420221722795178737"
     },
     "user_tz": -540
    },
    "id": "0d82d9a0",
    "outputId": "59728230-01ca-4147-f154-29157c466be4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
      "What is 13 raised to the .3432 power?\u001b[32;1m\u001b[1;3m```text\n",
      "13**0.3432\n",
      "```\n",
      "...numexpr.evaluate(\"13**0.3432\")...\n",
      "\u001b[0m\n",
      "Answer: \u001b[33;1m\u001b[1;3m2.4116004626599237\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is 13 raised to the .3432 power?',\n",
       " 'answer': 'Answer: 2.4116004626599237'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_math = LLMMathChain.from_llm(openai, verbose = True) # verbose 상세 로깅 활성화\n",
    "llm_math.invoke(\"What is 13 raised to the .3432 power?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79fbbde5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1731428370577,
     "user": {
      "displayName": "킹승영",
      "userId": "12420221722795178737"
     },
     "user_tz": -540
    },
    "id": "79fbbde5",
    "outputId": "24237c2f-c862-4a34-ee0e-20ea043a5f6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate a math problem into a expression that can be executed using Python's numexpr library. Use the output of running this code to answer the question.\n",
      "\n",
      "Question: ${{Question with math problem.}}\n",
      "```text\n",
      "${{single line mathematical expression that solves the problem}}\n",
      "```\n",
      "...numexpr.evaluate(text)...\n",
      "```output\n",
      "${{Output of running the code}}\n",
      "```\n",
      "Answer: ${{Answer}}\n",
      "\n",
      "Begin.\n",
      "\n",
      "Question: What is 37593 * 67?\n",
      "```text\n",
      "37593 * 67\n",
      "```\n",
      "...numexpr.evaluate(\"37593 * 67\")...\n",
      "```output\n",
      "2518731\n",
      "```\n",
      "Answer: 2518731\n",
      "\n",
      "Question: 37593^(1/5)\n",
      "```text\n",
      "37593**(1/5)\n",
      "```\n",
      "...numexpr.evaluate(\"37593**(1/5)\")...\n",
      "```output\n",
      "8.222831614237718\n",
      "```\n",
      "Answer: 8.222831614237718\n",
      "\n",
      "Question: {question}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(llm_math.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c9fa06",
   "metadata": {
    "id": "d2c9fa06"
   },
   "source": [
    "### 2. generic chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e67fb8b",
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1731428373688,
     "user": {
      "displayName": "킹승영",
      "userId": "12420221722795178737"
     },
     "user_tz": -540
    },
    "id": "1e67fb8b"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0157a596",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1731428373965,
     "user": {
      "displayName": "킹승영",
      "userId": "12420221722795178737"
     },
     "user_tz": -540
    },
    "id": "0157a596"
   },
   "outputs": [],
   "source": [
    "# 정규식을 이용해 주어진 텍스트에서 반복되는 줄바꿈을 하나로 변환하고, 탭을 스페이스로 변환하는 함수를 작성\n",
    "\n",
    "def transform_func(inputs: dict) -> dict:\n",
    "    text = inputs[\"text\"]\n",
    "    # replace multiple new lines and multiple spaces with a single one\n",
    "    text = re.sub(r'(\\r\\n|\\r|\\n){2,}', r'\\n', text) # 여러 개의 줄바꿈(\\r\\n, \\r, \\n)이 2개 이상 연속되면, 이를 하나의 \\n으로 대체\n",
    "    text = re.sub(r'[ \\t]+', ' ', text) # 여러 개의 공백 또는 탭 문자가 연속되면, 이를 하나의 공백으로 대체\n",
    "    return {\"output_text\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aa5b94c",
   "metadata": {
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1731428376483,
     "user": {
      "displayName": "킹승영",
      "userId": "12420221722795178737"
     },
     "user_tz": -540
    },
    "id": "5aa5b94c"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import TransformChain\n",
    "\n",
    "# TransformChain: langchain 라이브러리에서 제공하는 변환 체인 객체\n",
    "\n",
    "clean_extra_spaces_chain = TransformChain(input_variables=[\"text\"],\n",
    "                                          output_variables=[\"output_text\"],\n",
    "                                          transform=transform_func\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4youCvPLPEX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "executionInfo": {
     "elapsed": 296,
     "status": "ok",
     "timestamp": 1731428473531,
     "user": {
      "displayName": "킹승영",
      "userId": "12420221722795178737"
     },
     "user_tz": -540
    },
    "id": "c4youCvPLPEX",
    "outputId": "84058bef-e0d2-4e74-8046-4847b19386f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-cbdc363b7c40>:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  clean_extra_spaces_chain.run('A random text with some irregular spacing.\\n\\n\\n Another one here as well.')\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'A random text with some irregular spacing.\\n Another one here as well.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_extra_spaces_chain.run('A random text with some irregular spacing.\\n\\n\\n Another one here as well.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "830b6cd3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 273,
     "status": "ok",
     "timestamp": 1731428476624,
     "user": {
      "displayName": "킹승영",
      "userId": "12420221722795178737"
     },
     "user_tz": -540
    },
    "id": "830b6cd3",
    "outputId": "2734a867-a14b-4f5f-9d06-eb15b8535466"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'A random text with some irregular spacing.\\n\\n\\n Another one here as well.',\n",
       " 'output_text': 'A random text with some irregular spacing.\\n Another one here as well.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_extra_spaces_chain.invoke('A random text with some irregular spacing.\\n\\n\\n Another one here as well.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6bf5e7",
   "metadata": {
    "id": "6b6bf5e7"
   },
   "source": [
    "### 3. sequential chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8383712e",
   "metadata": {
    "id": "8383712e"
   },
   "source": [
    "- PromptTemplate과 LLMChain을 이용해 원하는 스타일로 텍스트를 변환하는 프롬프트 작성\n",
    "- SequentialChain으로 TransformChain과 LLMChain을 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3eb9b4c",
   "metadata": {
    "executionInfo": {
     "elapsed": 302,
     "status": "ok",
     "timestamp": 1731428381854,
     "user": {
      "displayName": "킹승영",
      "userId": "12420221722795178737"
     },
     "user_tz": -540
    },
    "id": "c3eb9b4c"
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "\n",
    "# template: 텍스트를 특정 스타일로 바꿔서 표현하도록 지시\n",
    "\n",
    "template = \"\"\"Paraphrase this text:\n",
    "{output_text}\n",
    "In the style of a {style}.\n",
    "Paraphrase: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "588c8736",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1731428382931,
     "user": {
      "displayName": "킹승영",
      "userId": "12420221722795178737"
     },
     "user_tz": -540
    },
    "id": "588c8736",
    "outputId": "93bf324f-f409-4781-9121-6c19852a2a65"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-13986d33b028>:5: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  style_paraphrase_chain = LLMChain(llm = openai, prompt = prompt,\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(input_variables = [\"style\", \"output_text\"], template = template)\n",
    "\n",
    "# LLMChain: LLM을 사용하여 주어진 프롬프트를 실행하는 체인\n",
    "\n",
    "style_paraphrase_chain = LLMChain(llm = openai, prompt = prompt,\n",
    "                                  output_key = 'final_output'\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70816303",
   "metadata": {
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1731428480487,
     "user": {
      "displayName": "킹승영",
      "userId": "12420221722795178737"
     },
     "user_tz": -540
    },
    "id": "70816303"
   },
   "outputs": [],
   "source": [
    "# 여러 chain 순차적 실행\n",
    "sequential_chain = SequentialChain(chains = [clean_extra_spaces_chain,\n",
    "                                             style_paraphrase_chain],\n",
    "                                             input_variables = ['text', 'style'],\n",
    "                                             output_variables = ['final_output']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df89e946",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1686,
     "status": "ok",
     "timestamp": 1731428484187,
     "user": {
      "displayName": "킹승영",
      "userId": "12420221722795178737"
     },
     "user_tz": -540
    },
    "id": "df89e946",
    "outputId": "7fa58631-4fa4-4978-847d-e8cb5eea376d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '\\nChains allow us to combine multiple \\n\\n\\n\\ncomponents together to create a single, coherent application. \\n\\n\\nFor example, we can create a chain that takes user input, \\t format it with a\\nPromptTemplate, \\n\\n\\nand then passes the formatted response to an LLM. We can build more complex chains by\\ncombining \\t multiple chains together, or by \\n\\n\\n\\n\\ncombining chains with other components.\\n',\n",
       " 'style': 'a 90s rapper',\n",
       " 'final_output': 'Yo, chains be like the glue that sticks all the pieces together to make one dope app. Like, we can make a chain that grabs what the user types, dresses it up with a PromptTemplate, and then hands it off to an LLM. And if we wanna get real fancy, we can mix and match chains or throw in some other components to make it even more fly.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"\"\"\n",
    "Chains allow us to combine multiple \\n\\n\\n\n",
    "components together to create a single, coherent application. \\n\\n\n",
    "For example, we can create a chain that takes user input, \\t format it with a\n",
    "PromptTemplate, \\n\\n\n",
    "and then passes the formatted response to an LLM. We can build more complex chains by\n",
    "combining \\t multiple chains together, or by \\n\\n\\n\\n\n",
    "combining chains with other components.\n",
    "\"\"\"\n",
    "\n",
    "sequential_chain.invoke({'text': input_text, 'style': 'a 90s rapper'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffe97cd0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1750,
     "status": "ok",
     "timestamp": 1731428486188,
     "user": {
      "displayName": "킹승영",
      "userId": "12420221722795178737"
     },
     "user_tz": -540
    },
    "id": "ffe97cd0",
    "outputId": "c2a7a699-9221-4504-84bb-dd4451e172b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chains be like the glue that sticks all the pieces together to make one dope app. You can mix and match different chains to make it all flow smoothly. Like, you can take user input, jazz it up with a PromptTemplate, and then send it off to an LLM. And if you wanna get real fancy, you can stack chains on top of each other or mix them with other cool stuff.\n"
     ]
    }
   ],
   "source": [
    "result = sequential_chain.invoke({'text': input_text, 'style': 'a 90s rapper'})\n",
    "print(result['final_output'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
